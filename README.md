# markov-chain-disc

A simple markov chain example for discrete state and time. This model assumes probabilities are independent at any time t and thus any given state is independent of previous states.

The only input is number of initial states. 
The only output is the transition matrix in which stationarity is reached and the time at which it is reached. 

This was a university assignment and one of the first functions I wrote while learning R. It's of little use if not for some basic understanding of simple stochastic processes. 
